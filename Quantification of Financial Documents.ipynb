{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis: Quantification of Financial Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The efficient market hypothesis assumes that the market price is reflective of all available information about a given asset. Markets over the last few decades, as reflected by hedge funds’ recent inabilities to outperform their benchmarks, have become more efficient. However, pockets of inefficiency remain related to the processing of market participants’ sentiment on individual assets or classes of assets. Indeed, sentiment can be seen as a real-time interpretation of the information being brought to the market by different players. For example, in earnings calls or securities filings, this is management bringing their views into the market. On social media, this could include individual investors on different platforms voicing their sentiment on a given stock, which could indicate the market actions (i.e. buy, sell, hold) they may pursue. Monitoring and identifying discrepancies between raw information and the sentiment of these actors is invaluable in capturing the remaining alpha in financial markets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today's Tasks: Going from an ACCURACY of 33.33% to more than 80%"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, we will build simple models, that will show the importance of context in unstructed financial datasets. The models will take as an input any financial statement (e.g. \"Assets in the private credit industry today total more than $600 billion, up about six fold since the year 2000.\") and quantify it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following exercise, we will start with a simple statistical model (Financial-Sentiment-V1), where we use pre-trained Word Embeddings (GloVe) to represent each word in the corpus and combine these embeddings to obtain the sentiment. Later, we will build more sophisticated models (Financial-Sentiment-V2 and Financial-Sentiment-V3) that further incorporates Recurrent Neural Network (RNN) and Long Short Term Memory Units (LSTM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Financial-Sentiment-V1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the required packages on this notebook. Press Shift+Enter on each cell to execute them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Dataset (Samples from Earnings Call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the dataset using the code below. \n",
    "The dataset contains 14727 sentences (strings) and their corresponding integer labels between -1 and 1 (-1:Negative; 0:Neutral; 1:Positive). \n",
    "\n",
    "<img src='SampleData.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv('EC_data.csv')\n",
    "X = list(Data['Sentence'])\n",
    "Y = Data['MyScore']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see other sentences in the dataset, you can change $index$ below and run the cell to print sentences from X and corresponding labels from Y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our tactical opportunities business raised $700 million during the quarter, had an additional closing in October, which, as Tony mentioned, brought the strategy to $4.4 billion in size, which is really good for a start-up type of business that doesn't fit any particular vertical silo in the institutional community it invests across. 1\n"
     ]
    }
   ],
   "source": [
    "index = 10\n",
    "print(X[index], (Y[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Overview of the Financial-Sentiment-V1\n",
    "\n",
    "In this part, we are going to implement a baseline statistical model called \"Financial-Sentiment-V1\".\n",
    "\n",
    "The input for this case will be any sentence from our dataset (e.g. \"Assets in the private credit industry today total more than $600 billion, up about six fold since the year 2000\"), and the output will be a vector of shape (3,1) where each value will be the probability of the class being true, that is then passed to an argmax layer to extract the index of the most likely output.\n",
    "\n",
    "Being a classification problem, we will convert our labels to normalize them for the softmax classifier. Let's convert $Y$ ($(m, 1)$) into a \"one-hot representation\" $(m, 3)$, where each row is a one-hot vector giving the label of one example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LB = LabelBinarizer()\n",
    "LB.fit(Y)\n",
    "Y_OH = LB.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 is converted into one hot [0 0 1]\n"
     ]
    }
   ],
   "source": [
    "index = 10\n",
    "print(Y[index], \"is converted into one hot\", Y_OH[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - Implementing Financial-Sentiment-V1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Feature Representation of Text\n",
    "\n",
    "In almost all NLP tasks, the first step is to convert input text into a representation that the machine can process. There are multiple ways to represent text, some statistical and some contextual. Below we will go through a few ways to represent any text dataset to understand how these work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Vectors\n",
    "\n",
    "At the most basic level, Count Vectors represent the $count$ of each word in an example. We build a dictionary of every word present in the dataset, and then each count vector has the size $(C,1)$, where $C$ is the size of the dictionary. Given such a representation, the words in each sentence are jumbled and thus lose a lot of the contextual information in the data. Let's see an example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "\n",
    "# fit the data using count vectorizer object\n",
    "count_vect.fit(X)\n",
    "    \n",
    "# transform the data using count vectorizer object\n",
    "X_count =  count_vect.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what the count vectors look like for a sample of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Stock markets in the U. S. which initially declined up to 8%, have now recovered in only three weeks to regain record levels.\\nInterest rates have started to decline slowly as market peaks, as investors recognize that the Fed will act with prudence, not to stifle the economic recovery.', 'This receivable, contrary to what you might think, actually increased from the previous year despite our very substantial payout of distributions over the same period.', 'While a challenging single quarter for the industry and for us, on a long-term basis, as Steve have mentioned, BAAM has delivered net returns 50% greater than the market with about one-third of the volatility over the past 15 years.', \"Finally, I'd like to highlight an important emerging dimension confirms business and economic model that is important to consider pertaining to new businesses like Real Estate core+ and Core Private Equity, which together will be approaching $17 billion in the second quarter, up from zero just over two years ago.\", 'Evidencing the carryover of this momentum into 2015, we should point out that realization activity remains robust, as we already have closed or announced $6 billion of realizations in the first few weeks of the first quarter alone.', 'This consistency and stability deepens our relationships with our limited partners and results in them wanting to do more business with us.', \"First, we completed the spin of our advisory businesses on October 1, and so 2015 was without what is typically those businesses' seasonally strongest quarter.\", 'In Hedge Funds, the strategies are either designed to have a third of the volatility of the S&P, be market neutral, long, short or relate to asset growth of alternative managers, all of which is a step or move from public markets.', \"As you know, our eighth global real estate fund was activated this year and we'll experience its first quarter of full fees in the current quarter and first year of full fees in 2016.\", \"In fact, as Steve outlined, several of our newest and largest fundraisers have resulted in the firm reaching caps or capacity, evidencing the demand for alternatives in general, and the power of Blackstone's track record and brand in particular.\"]\n",
      "['15', '17', '2015', '50', '6', '8', 'a', 'about', 'act', 'activity', 'actually', 'ago', 'alone', 'already', 'an', 'and', 'announced', 'approaching', 'as', 'baam', 'basis', 'be', 'billion', 'business', 'businesses', 'carryover', 'challenging', 'closed', 'confirms', 'consider', 'contrary', 'core', 'd', 'decline', 'declined', 'delivered', 'despite', 'dimension', 'distributions', 'economic', 'emerging', 'equity', 'estate', 'evidencing', 'fed', 'few', 'finally', 'first', 'for', 'from', 'greater', 'has', 'have', 'highlight', 'i', 'important', 'in', 'increased', 'industry', 'initially', 'interest', 'into', 'investors', 'is', 'just', 'levels', 'like', 'long', 'market', 'markets', 'mentioned', 'might', 'model', 'momentum', 'net', 'new', 'not', 'now', 'of', 'on', 'one', 'only', 'or', 'our', 'out', 'over', 'past', 'payout', 'peaks', 'period', 'pertaining', 'point', 'previous', 'private', 'prudence', 'quarter', 'rates', 'real', 'realization', 'realizations', 'receivable', 'recognize', 'record', 'recovered', 'recovery', 'regain', 'remains', 'returns', 'robust', 's', 'same', 'second', 'should', 'single', 'slowly', 'started', 'steve', 'stifle', 'stock', 'substantial', 'term', 'than', 'that', 'the', 'think', 'third', 'this', 'three', 'to', 'together', 'two', 'u', 'up', 'us', 'very', 'volatility', 'we', 'weeks', 'what', 'which', 'while', 'will', 'with', 'year', 'years', 'you', 'zero']\n",
      "[[0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      "  0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 2 0 0 0 2 0 0 1 1 0 1 0 0 1 0 0 1 1 0 0\n",
      "  0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 1 1 1 1 0 0\n",
      "  0 1 0 0 0 0 1 1 0 1 1 0 0 0 1 3 0 0 0 1 4 0 0 1 1 0 0 0 0 1 0 1 0 1 1 0\n",
      "  0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      "  1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 2 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1\n",
      "  0 1 0]\n",
      " [1 0 0 1 0 0 2 1 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 2 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0\n",
      "  0 0 1 0 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 4 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0\n",
      "  1 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 2 0 1 0 0 0 1 1 1 1 0 0 0 1 1 0 2 1 0 0 0\n",
      "  0 1 0 1 1 1 1 0 0 0 1 0 0 1 0 0 0 1 1 2 1 0 0 0 0 0 0 1 1 0 2 0 0 0 0 0\n",
      "  1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 3 1 1 0 1 0 0 0 0 0 0 1 0 1 0 0\n",
      "  1 0 1]\n",
      " [0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 1 0 1 0 2 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      "  0 1 0 0 0 0 3 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0\n",
      "  1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 3 0 0 1 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0\n",
      "  0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "Sample_Count = vectorizer.fit_transform(X[:5])\n",
    "print(X[:5])\n",
    "print(vectorizer.get_feature_names())\n",
    "print(Sample_Count.toarray())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF Vectors\n",
    "\n",
    "Term Frequency - Inverse Document Frequency (TF-IDF) vector representation accounts for the the most commonly occuring words in a document which empirically do not provide much information. We can think of this representation as 'Normalizing the Count Vectors' with respect to the document frequency, where document frequency is the number of documents containing that term out of the total number of documents. \n",
    "\n",
    "For both Count Vectors and TF-IDF Vectors, we can also convert the document based on co-occuring words (n-grams) or even the character level. \n",
    "\n",
    "Let's see an example of TF-IDF Vectors below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(X)\n",
    "X_tfidf =  tfidf_vect.transform(X)\n",
    "\n",
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(X)\n",
    "X_tfidf_ngram =  tfidf_vect_ngram.transform(X)\n",
    "\n",
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram_chars.fit(X)\n",
    "X_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "vectorizer = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "Sample_Count = vectorizer.fit_transform(X[:5])\n",
    "print(X[:5])\n",
    "print(vectorizer.get_feature_names())\n",
    "print(Sample_Count.shape)\n",
    "print(Sample_Count.toarray())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram level tf-idf\n",
    "vectorizer = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "Sample_Count = vectorizer.fit_transform(X[:5])\n",
    "print(X[:5])\n",
    "print(vectorizer.get_feature_names())\n",
    "print(Sample_Count.shape)\n",
    "print(Sample_Count.toarray())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# characters level tf-idf\n",
    "vectorizer = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "Sample_Count = vectorizer.fit_transform(X[:5])\n",
    "print(X[:5])\n",
    "print(vectorizer.get_feature_names())\n",
    "print(Sample_Count.shape)\n",
    "print(Sample_Count.toarray())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Embeddings\n",
    "Word embeddings are generally obtained by building a network that can predict the next word, given a part of the sentence. Therefore, these word embeddings generally have contextual meaning hidden in them. Given properly trained word embeddings, they are able to capture similarities between different words. For example, $King:Queen::Man:?$ should produce $Woman$. Thus these word embeddings provide much more meaning to the represetation ofthe dataset. \n",
    "\n",
    "Below, we will use pretrained 50-dimensional GloVe embeddings for our task (Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation.). Run the following cell to load the pre-trained word-vector representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map\n",
    "\n",
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to clean up the text to remove unnecessary characters in the data, as well as standardize the data with respect to textcase. The function below implements this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_document(s):\n",
    "    punctuation = string.punctuation.replace(\"$\",\"\")\n",
    "    punctuation = punctuation.replace(\"%\",\"\")\n",
    "    punctuation = punctuation.replace(\".\",\"\")\n",
    "    regex = re.compile('[%s]' % re.escape(punctuation + '\\n\\n' + '\\t\\t'))\n",
    "    doco_clean = regex.sub('', s)\n",
    "    doco_clean = doco_clean.split(' ');\n",
    "    doco_clean = [word.lower() for word in doco_clean if len(word) > 0];\n",
    "    return doco_clean;\n",
    "\n",
    "# X_train_clean = [clean_document(doc) for doc in X_train];\n",
    "# sentences = [' '.join(r) for r in X_train_clean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 The Model for Financial-Sentiment-V1\n",
    "\n",
    "The model below converts each word in a sentence in to the respective word embedding vectors and averages them out. This is a very basic model where we will see that a Bag-Of-Words approach again loses the context in the data, since the averaging of all vectors does not keep the ordering of words in place. Therefore, while the word embeddings themselves were useful, averaging them out loses information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "    \n",
    "    # Step 1: Clean the sentence for unwanted punctuations (≈ 1 line)\n",
    "    clean_sentence = clean_document(sentence)\n",
    "    clean_sentence = ' '.join(clean_sentence)\n",
    "    # Step 2: Split sentence into list of lower case words (≈ 1 line)\n",
    "    words = [i for i in clean_sentence.split()]\n",
    "\n",
    "    # Initialize the average word vector, should have the same shape as your word vectors.\n",
    "    avg = np.zeros((50,))\n",
    "    \n",
    "    # Step 3: average the word vectors. You can loop over the words in the list \"words\".\n",
    "    for w in words:\n",
    "        if w in word_to_vec_map:\n",
    "            avg += word_to_vec_map[w]\n",
    "    avg = avg / len(words)\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg =  [ 0.26956385  0.16672588  0.14773427 -0.02106142  0.26837015  0.0862631\n",
      " -0.51499381 -0.3032405  -0.09628022  0.00788788 -0.03455082  0.04363842\n",
      " -0.27352154 -0.07371946  0.32823194  0.04443627 -0.02299358  0.08622424\n",
      " -0.45268815 -0.30439096  0.45163981 -0.0642255   0.1031345  -0.29393677\n",
      " -0.15614854 -1.23140188  0.03060142 -0.05696419  0.22098765 -0.06096092\n",
      "  3.15196808  0.24857712 -0.22906296 -0.00623649  0.18017722 -0.07002043\n",
      " -0.01247919  0.22210315  0.17086285 -0.18696877 -0.12483815 -0.11889538\n",
      "  0.10272015 -0.02692988 -0.23968721  0.10922885 -0.06557547  0.25517996\n",
      " -0.0555085   0.08912108]\n"
     ]
    }
   ],
   "source": [
    "avg = sentence_to_avg(\"We completed two acquisitions during the year adding a 3 million gallon motor-fuel business to our mix and a bolt-on acquisition to our Cylinder Exchange program.\", word_to_vec_map)\n",
    "print(\"avg = \", avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, y, word_to_vec_map, learning_rate = 0.01, num_iterations = 400):\n",
    "    \n",
    "    np.random.seed(1)\n",
    "\n",
    "    # Define number of training examples\n",
    "    m = y.shape[0]                          # number of training examples\n",
    "    n_y = 3                                 # number of classes  \n",
    "    n_h = 50                                # dimensions of the GloVe vectors \n",
    "    \n",
    "    # Initialize parameters using Xavier initialization\n",
    "    W = np.random.randn(n_y, n_h) / np.sqrt(n_h)\n",
    "    b = np.zeros((n_y,))\n",
    "    \n",
    "    # Optimization loop\n",
    "    for t in range(num_iterations):                       # Loop over the number of iterations\n",
    "        for i in range(m):                                # Loop over the training examples\n",
    "            \n",
    "            # Average the word vectors of the words from the i'th training example\n",
    "            avg = sentence_to_avg(x[i], word_to_vec_map)\n",
    "\n",
    "            # Forward propagate the avg through the softmax layer\n",
    "            z = np.dot(W, avg) + b\n",
    "            a = softmax(z)\n",
    "\n",
    "            # Compute cost using the i'th training label's one hot representation and \"A\" (the output of the softmax)\n",
    "            cost = -np.sum(np.multiply(y[i], np.log(a)))\n",
    "            \n",
    "            # Compute gradients \n",
    "            dz = a - y[i]\n",
    "            dW = np.dot(dz.reshape(n_y,1), avg.reshape(1, n_h))\n",
    "            db = dz\n",
    "\n",
    "            # Update parameters with Stochastic Gradient Descent\n",
    "            W = W - learning_rate * dW\n",
    "            b = b - learning_rate * db\n",
    "        \n",
    "        if t % 100 == 0:\n",
    "            print(\"Epoch: \" + str(t) + \" --- cost = \" + str(cost))\n",
    "            pred = predict(x, y, W, b, word_to_vec_map)\n",
    "\n",
    "    return pred, W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, y, W, b, word_to_vec_map):\n",
    "\n",
    "    m = len(x)\n",
    "    pred = np.zeros((m, 1))\n",
    "    Y_value = np.zeros((m, 1))\n",
    "    \n",
    "    for j in range(m):                       # Loop over training examples\n",
    "        \n",
    "        # Split jth test example (sentence) into list of lower case words\n",
    "        clean_sentence = clean_document(x[j])\n",
    "        clean_sentence = ' '.join(clean_sentence)\n",
    "        # Step 2: Split sentence into list of lower case words (≈ 1 line)\n",
    "        words = [i for i in clean_sentence.split()]\n",
    "        \n",
    "        # Average words' vectors\n",
    "        avg = np.zeros((50,))\n",
    "        for w in words:\n",
    "            if w in word_to_vec_map:\n",
    "                avg += word_to_vec_map[w]\n",
    "        avg = avg/len(words)\n",
    "\n",
    "        # Forward propagation\n",
    "        Z = np.dot(W, avg) + b\n",
    "        A = softmax(Z)\n",
    "        pred[j] = np.argmax(A)\n",
    "        Y_value[j] = np.argmax(y[j])\n",
    "        \n",
    "    pred[pred == 0] = -1\n",
    "    pred[pred == 1] = 0\n",
    "    pred[pred == 2] = 1\n",
    "    \n",
    "    Y_value[Y_value == 0] = -1\n",
    "    Y_value[Y_value == 1] = 0\n",
    "    Y_value[Y_value == 2] = 1\n",
    "        \n",
    "    print(\"Accuracy: \"  + str(np.mean((pred[:] == Y_value.reshape(Y_value.shape[0],1)[:]))))\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 --- cost = 1.465530363046367\n",
      "Accuracy: 0.5883198849564593\n",
      "Epoch: 100 --- cost = 0.9504478543614028\n",
      "Accuracy: 0.6306622992729888\n",
      "Epoch: 200 --- cost = 0.9388129184663074\n",
      "Accuracy: 0.6325796916193976\n",
      "Epoch: 300 --- cost = 0.9298192010497282\n",
      "Accuracy: 0.6339378445314372\n",
      "[[ 1.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y_OH, test_size=.15)\n",
    "pred, W, b = model(X_train, Y_train, word_to_vec_map)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 - Examine performance on Test (Unseen) Data\n",
    "\n",
    "Below we can see how the model performed on the training data and test data. While it is a significant increase from just randomly classifying each sentence in to one of the three labels, it still may not have significant value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Accuracy: 0.6341775185747384\n",
      "Test set:\n",
      "Accuracy: 0.6285067873303167\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set:\")\n",
    "pred_train = predict(X_train, Y_train, W, b, word_to_vec_map)\n",
    "print('Test set:')\n",
    "pred_test = predict(X_test, Y_test, W, b, word_to_vec_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Financial-Sentiment-V2 Using Sequential Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Model Overview\n",
    "\n",
    "Text datasets are generally directional datasets, where the context/meaning depends on the ordering of each word within that sentence. Sequential Neural Networks provide us with a way to analyze these datasets in contextual manner than being completely statistical. Below, we will see two types of networks: 1) Recurrent Neural Networks (RNN), and 2) Long Short Term Memory Units (LSTM) and compare these with the model built above.\n",
    "\n",
    "An essential component of a neural network analyzing text data is the Embedding Layer. This embedding layer serves as the bridge between $text$ and its $numerical$ $representation$ that the machine processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Embedding Layer\n",
    "\n",
    "The embedding layer takes as input the indices of each word in the sentence and outputs the corresponding word vector representation. This embedding layer can use pre-trained word embedding vectors, or these can be tuned/trained on the fly as well. In the models below we will use the same pre-trained GloVe embeddings as above.\n",
    "\n",
    "Run the following cell to load the required packages and libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation, SimpleRNN\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will again need to clean up the text as a pre-processing step for input to the neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_document(s):\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation + '\\n\\n' + '\\t\\t'))\n",
    "    doco_clean = regex.sub('', s)\n",
    "    doco_clean = doco_clean.split(' ');\n",
    "    doco_clean = [word.lower() for word in doco_clean if len(word) > 0];\n",
    "    return doco_clean;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data again and do some pre-processing for our labels, i.e. convert these to one-hot-encodings, and clean up the sentences from the earnings calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sahil/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/Users/sahil/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Data = pd.read_csv('EC_data.csv')\n",
    "X = list(Data['Sentence'])\n",
    "Y = Data['MyScore']\n",
    "\n",
    "y = Y\n",
    "y[Y > 0] = 1\n",
    "y[Y < 0] = 2\n",
    "\n",
    "# Obtain a One-hot Y array for each review label.\n",
    "y = to_categorical(y);\n",
    "\n",
    "X_clean = [clean_document(doc) for doc in X];\n",
    "sentences = [' '.join(r) for r in X_clean]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will tokenize each word in the dataset to unique identifier for that word, which could then be used by the embedding layer to convert this index to its corresponding word vector representation. Here, we will again use the pre-trained GloVe embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer();\n",
    "tokenizer.fit_on_texts(sentences);\n",
    "text_sequences = np.array(tokenizer.texts_to_sequences(sentences));\n",
    "sequence_dict = tokenizer.word_index;\n",
    "word_dict = dict((num, val) for (val, num) in sequence_dict.items());\n",
    "\n",
    "Glove_dim = 50\n",
    "embeddings_index = dict();\n",
    "with open('glove.6B.50d.txt') as f:\n",
    "    for line in f:\n",
    "        values = line.split();\n",
    "        word = values[0];\n",
    "        coefs = np.asarray(values[1:], dtype='float32');\n",
    "        embeddings_index[word] = coefs;\n",
    "        \n",
    "vocab_size = len(sequence_dict);\n",
    "embeddings_matrix = np.zeros((vocab_size+1, Glove_dim));\n",
    "for word, i in sequence_dict.items():\n",
    "    embedding_vector = embeddings_index.get(word);\n",
    "    if embedding_vector is not None:\n",
    "        embeddings_matrix[i] = embedding_vector;\n",
    "\n",
    "# Generate encoded reviews\n",
    "reviews_encoded = [];\n",
    "for i,review in enumerate(X_clean):\n",
    "    reviews_encoded.append([sequence_dict[x] for x in review]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the distribution of the lengths of sentences in our dataset. This would allow us to fix the length of the sentence that goes as input to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a Histogram of length of reviews\n",
    "lengths = [len(x) for x in reviews_encoded];\n",
    "with plt.xkcd():\n",
    "    plt.hist(lengths, bins=range(100))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram above shows that we could use a cap of 50 words for each sentence as almost all of the distribution is captured at this length.\n",
    "\n",
    "Next, we will truncate all sentences for a cap of 50 words and pad those sentences with length less than 50. We will also randomny shuffle the data, so as not to overfit the neural network to any particular part of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate and Pad reviews at a Maximum cap of 50 words.\n",
    "max_cap = 50;\n",
    "X_pad = pad_sequences(reviews_encoded, maxlen=max_cap, truncating='post', padding='post')\n",
    "\n",
    "# Get a randomized sequence of positions to shuffle reviews\n",
    "np.random.seed(1024);\n",
    "random_posits = np.arange(len(X))\n",
    "np.random.shuffle(random_posits);\n",
    "\n",
    "# Shuffle X and Y\n",
    "X_pad = X_pad[random_posits];\n",
    "y = y[random_posits];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the last step before the model, we need to split the data in to training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_pad,y, test_size=.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Building the Model\n",
    "\n",
    "Below, we will implement two models using RNNs and LSTMs. In both cases, we will start with the embedding layer which then feeds in to the RNN/LSTM units. This then goes in to a Feed Forward Neural Network and then finally to a classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Recurrent Neural Network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 50, 50)            969650    \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 60)                6660      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 3)                 183       \n",
      "=================================================================\n",
      "Total params: 980,153\n",
      "Trainable params: 10,503\n",
      "Non-trainable params: 969,650\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "12517/12517 [==============================] - 4s 284us/step - loss: 0.6003 - acc: 0.6647\n",
      "Epoch 2/10\n",
      "12517/12517 [==============================] - 2s 175us/step - loss: 0.5913 - acc: 0.6669\n",
      "Epoch 3/10\n",
      "12517/12517 [==============================] - 2s 186us/step - loss: 0.5918 - acc: 0.6675\n",
      "Epoch 4/10\n",
      "12517/12517 [==============================] - 2s 183us/step - loss: 0.5921 - acc: 0.6657\n",
      "Epoch 5/10\n",
      "12517/12517 [==============================] - 2s 174us/step - loss: 0.5901 - acc: 0.6667\n",
      "Epoch 6/10\n",
      "12517/12517 [==============================] - 2s 174us/step - loss: 0.5896 - acc: 0.6669\n",
      "Epoch 7/10\n",
      "12517/12517 [==============================] - 2s 172us/step - loss: 0.5892 - acc: 0.6662\n",
      "Epoch 8/10\n",
      "12517/12517 [==============================] - 2s 177us/step - loss: 0.5893 - acc: 0.6687\n",
      "Epoch 9/10\n",
      "12517/12517 [==============================] - 2s 177us/step - loss: 0.5891 - acc: 0.6672\n",
      "Epoch 10/10\n",
      "12517/12517 [==============================] - 2s 167us/step - loss: 0.5888 - acc: 0.6671\n",
      "2210/2210 [==============================] - 1s 304us/step\n",
      "\n",
      "Test accuracy =  0.6684766404229592\n"
     ]
    }
   ],
   "source": [
    "model = Sequential();\n",
    "model.add(Embedding(len(word_dict)+1, max_cap, input_length=max_cap, weights=[embeddings_matrix], trainable=False));\n",
    "model.add(SimpleRNN(60));\n",
    "model.add(Dense(60, activation='relu'));\n",
    "model.add(Dense(3, activation='softmax'));\n",
    "print(model.summary());\n",
    "optimizer = Adam(lr=0.01, decay=0.001);\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "# fit model\n",
    "model.fit(X_train, Y_train, batch_size=64, epochs=10)\n",
    "\n",
    "loss, acc = model.evaluate(X_test, Y_test)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 LSTM\n",
    "\n",
    "While RNN is a sequential neural network, it suffers from Vanishing/Exploding Gradients that act as Memory Loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 50, 50)            969650    \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 60)                26640     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 3)                 183       \n",
      "=================================================================\n",
      "Total params: 1,000,133\n",
      "Trainable params: 30,483\n",
      "Non-trainable params: 969,650\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "12517/12517 [==============================] - 9s 735us/step - loss: 0.5874 - acc: 0.6755\n",
      "Epoch 2/10\n",
      "12517/12517 [==============================] - 7s 576us/step - loss: 0.5095 - acc: 0.7587\n",
      "Epoch 3/10\n",
      "12517/12517 [==============================] - 7s 571us/step - loss: 0.4423 - acc: 0.7986\n",
      "Epoch 4/10\n",
      "12517/12517 [==============================] - 7s 570us/step - loss: 0.4096 - acc: 0.8188\n",
      "Epoch 5/10\n",
      "12517/12517 [==============================] - 7s 571us/step - loss: 0.3842 - acc: 0.8338\n",
      "Epoch 6/10\n",
      "12517/12517 [==============================] - 7s 578us/step - loss: 0.3592 - acc: 0.8469\n",
      "Epoch 7/10\n",
      "12517/12517 [==============================] - 7s 595us/step - loss: 0.3298 - acc: 0.8640\n",
      "Epoch 8/10\n",
      "12517/12517 [==============================] - 7s 575us/step - loss: 0.3054 - acc: 0.8761\n",
      "Epoch 9/10\n",
      "12517/12517 [==============================] - 8s 634us/step - loss: 0.2785 - acc: 0.8904\n",
      "Epoch 10/10\n",
      "12517/12517 [==============================] - 8s 608us/step - loss: 0.2549 - acc: 0.9025\n",
      "2210/2210 [==============================] - 1s 409us/step\n",
      "\n",
      "Test accuracy =  0.8174962324254653\n"
     ]
    }
   ],
   "source": [
    "model = Sequential();\n",
    "model.add(Embedding(len(word_dict)+1, max_cap, input_length=max_cap, weights=[embeddings_matrix], trainable=False));\n",
    "model.add(LSTM(60));\n",
    "model.add(Dense(60, activation='relu'));\n",
    "model.add(Dense(3, activation='softmax'));\n",
    "print(model.summary());\n",
    "optimizer = Adam(lr=0.01, decay=0.001);\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "# fit model\n",
    "model.fit(X_train, Y_train, batch_size=64, epochs=10)\n",
    "\n",
    "loss, acc = model.evaluate(X_test, Y_test)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
